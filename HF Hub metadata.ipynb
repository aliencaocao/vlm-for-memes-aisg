{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-02-24T05:18:26.471732Z",
     "start_time": "2025-02-24T05:18:26.094732Z"
    }
   },
   "source": "from huggingface_hub import DatasetCardData, ModelCardData, EvalResult, metadata_update",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-24T07:06:33.448877Z",
     "start_time": "2025-02-24T07:06:33.433878Z"
    }
   },
   "cell_type": "code",
   "source": [
    "datasetcard = DatasetCardData(\n",
    "    language=\"en\",\n",
    "    license=\"gpl-3.0\",\n",
    "    annotations_creators=['found', 'expert-generated', 'machine-generated'],\n",
    "    language_creators=['found', 'expert-generated', 'machine-generated'],\n",
    "    multilinguality='multilingual',\n",
    "    source_datasets=['extended'],\n",
    "    task_categories=['text-generation', 'visual-question-answering', 'image-text-to-text'],\n",
    "    pretty_name='Offensive Memes in Singapore Context'\n",
    ")"
   ],
   "id": "a340a851a58c25b6",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-24T07:06:43.067165Z",
     "start_time": "2025-02-24T07:06:41.291453Z"
    }
   },
   "cell_type": "code",
   "source": "metadata_update(\"aliencaocao/multimodal_meme_classification_singapore\", datasetcard.to_dict(), repo_type=\"dataset\", overwrite=True)",
   "id": "85601b63915e69a4",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Program Files\\Python39\\lib\\site-packages\\huggingface_hub\\hf_api.py:9246: UserWarning: Warnings while validating metadata in README.md:\n",
      "- empty or missing yaml metadata in repo card\n",
      "  warnings.warn(f\"Warnings while validating metadata in README.md:\\n{message}\")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CommitInfo(commit_url='https://huggingface.co/datasets/aliencaocao/multimodal_meme_classification_singapore/commit/6e1ef9bf1a66ab9a201c60f5de37ef260eb8c0a6', commit_message='Update metadata with huggingface_hub', commit_description='', oid='6e1ef9bf1a66ab9a201c60f5de37ef260eb8c0a6', pr_url=None, repo_url=RepoUrl('https://huggingface.co/datasets/aliencaocao/multimodal_meme_classification_singapore', endpoint='https://huggingface.co', repo_type='dataset', repo_id='aliencaocao/multimodal_meme_classification_singapore'), pr_revision=None, pr_num=None)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-24T14:25:15.270598Z",
     "start_time": "2025-02-24T14:25:15.253589Z"
    }
   },
   "cell_type": "code",
   "source": [
    "qwen_eval_auroc = EvalResult(\n",
    "    task_type='image-classification',\n",
    "    dataset_type='aliencaocao/multimodal_meme_classification_singapore',\n",
    "    dataset_name='Offensive Memes in Singapore Context',\n",
    "    metric_type='roc_auc',\n",
    "    metric_value=0.8192,\n",
    "    task_name='Offensive Meme Classification',\n",
    "    dataset_split='test',\n",
    "    metric_name='AUROC',\n",
    ")\n",
    "qwen_eval_acc = EvalResult(\n",
    "    task_type='image-classification',\n",
    "    dataset_type='aliencaocao/multimodal_meme_classification_singapore',\n",
    "    dataset_name='Offensive Memes in Singapore Context',\n",
    "    metric_type='accuracy',\n",
    "    metric_value=0.8043,\n",
    "    task_name='Offensive Meme Classification',\n",
    "    dataset_split='test',\n",
    "    metric_name='Accuracy',\n",
    ")"
   ],
   "id": "41a9cd1e11980c45",
   "outputs": [],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-24T14:25:16.486876Z",
     "start_time": "2025-02-24T14:25:16.467918Z"
    }
   },
   "cell_type": "code",
   "source": [
    "qwen_modelcard = ModelCardData(\n",
    "    base_model='Qwen/Qwen2-VL-7B-Instruct',\n",
    "    datasets=['aliencaocao/multimodal_meme_classification_singapore'],\n",
    "    eval_results=[qwen_eval_auroc, qwen_eval_acc],\n",
    "    language='en',\n",
    "    library_name='transformers',\n",
    "    license='mit',\n",
    "    metrics=['accuracy', 'roc_auc'],\n",
    "    model_name='qwen2-vl-7b-rslora-offensive-meme-singapore',\n",
    "    pipeline_tag='image-text-to-text',\n",
    "    tags=['memes', 'offensive', 'singapore', 'vlm']\n",
    ")"
   ],
   "id": "86ad3fdaddec6958",
   "outputs": [],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-24T14:25:43.078937Z",
     "start_time": "2025-02-24T14:25:40.615857Z"
    }
   },
   "cell_type": "code",
   "source": "metadata_update(\"aliencaocao/qwen2-vl-7b-rslora-offensive-meme-singapore\", qwen_modelcard.to_dict(), repo_type=\"model\", overwrite=True)",
   "id": "25f0a35b7ca4b5c8",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CommitInfo(commit_url='https://huggingface.co/aliencaocao/qwen2-vl-7b-rslora-offensive-meme-singapore/commit/7528e8c320f844d5e1456294113a4ae48c2c5841', commit_message='Update metadata with huggingface_hub', commit_description='', oid='7528e8c320f844d5e1456294113a4ae48c2c5841', pr_url=None, repo_url=RepoUrl('https://huggingface.co/aliencaocao/qwen2-vl-7b-rslora-offensive-meme-singapore', endpoint='https://huggingface.co', repo_type='model', repo_id='aliencaocao/qwen2-vl-7b-rslora-offensive-meme-singapore'), pr_revision=None, pr_num=None)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-24T14:30:11.360239Z",
     "start_time": "2025-02-24T14:30:11.343239Z"
    }
   },
   "cell_type": "code",
   "source": [
    "llava_eval_auroc = EvalResult(\n",
    "    task_type='image-classification',\n",
    "    dataset_type='aliencaocao/multimodal_meme_classification_singapore',\n",
    "    dataset_name='Offensive Memes in Singapore Context',\n",
    "    metric_type='roc_auc',\n",
    "    metric_value=0.7345,\n",
    "    task_name='Offensive Meme Classification',\n",
    "    dataset_split='test',\n",
    "    metric_name='AUROC',\n",
    ")\n",
    "llava_eval_acc = EvalResult(\n",
    "    task_type='image-classification',\n",
    "    dataset_type='aliencaocao/multimodal_meme_classification_singapore',\n",
    "    dataset_name='Offensive Memes in Singapore Context',\n",
    "    metric_type='accuracy',\n",
    "    metric_value=0.7259,\n",
    "    task_name='Offensive Meme Classification',\n",
    "    dataset_split='test',\n",
    "    metric_name='Accuracy',\n",
    ")"
   ],
   "id": "90e4e0993d5b43f4",
   "outputs": [],
   "execution_count": 16
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-24T14:30:12.293239Z",
     "start_time": "2025-02-24T14:30:12.286241Z"
    }
   },
   "cell_type": "code",
   "source": [
    "qwen_modelcard = ModelCardData(\n",
    "    base_model='llava-hf/llava-v1.6-mistral-7b-hf',\n",
    "    datasets=['aliencaocao/multimodal_meme_classification_singapore'],\n",
    "    eval_results=[llava_eval_auroc, llava_eval_acc],\n",
    "    language='en',\n",
    "    library_name='transformers',\n",
    "    license='mit',\n",
    "    metrics=['accuracy', 'roc_auc'],\n",
    "    model_name='llava-1.6-mistral-7b-offensive-meme-singapore',\n",
    "    pipeline_tag='image-text-to-text',\n",
    "    tags=['memes', 'offensive', 'singapore', 'vlm']\n",
    ")"
   ],
   "id": "98ccd859f0ec6292",
   "outputs": [],
   "execution_count": 17
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-24T14:30:17.850479Z",
     "start_time": "2025-02-24T14:30:14.138863Z"
    }
   },
   "cell_type": "code",
   "source": "metadata_update(\"aliencaocao/llava-1.6-mistral-7b-offensive-meme-singapore\", qwen_modelcard.to_dict(), repo_type=\"model\", overwrite=True)",
   "id": "9ea9dc31c226243",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CommitInfo(commit_url='https://huggingface.co/aliencaocao/llava-1.6-mistral-7b-offensive-meme-singapore/commit/913d017414429daf4655e0fbb9c722246493ee46', commit_message='Update metadata with huggingface_hub', commit_description='', oid='913d017414429daf4655e0fbb9c722246493ee46', pr_url=None, repo_url=RepoUrl('https://huggingface.co/aliencaocao/llava-1.6-mistral-7b-offensive-meme-singapore', endpoint='https://huggingface.co', repo_type='model', repo_id='aliencaocao/llava-1.6-mistral-7b-offensive-meme-singapore'), pr_revision=None, pr_num=None)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 18
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
